# MirrorX GPU Configuration Override
# ============================================================================
#
# This file enables GPU support for the ML inference services.
#
# Usage:
#   docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
#
# Requirements:
#   - NVIDIA GPU with 16GB+ VRAM
#   - NVIDIA Container Toolkit installed
#   - Docker configured for GPU support
#
# Installation (Ubuntu):
#   # Install NVIDIA Container Toolkit
#   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
#   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
#   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
#   sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
#   sudo systemctl restart docker
#
# ============================================================================

version: '3.9'

services:
  # IDM-VTON with GPU
  idm-vton:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

  # LTX-2 with GPU
  ltx2:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
