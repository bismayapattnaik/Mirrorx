# MirrorX-VTON Training Configuration
# Optimized for IndiaAI Compute H100 GPUs

# ============================================
# Model Configuration
# ============================================
pretrained_model_name: "stabilityai/stable-diffusion-xl-base-1.0"
output_dir: "./checkpoints"

# ============================================
# LoRA Configuration
# ============================================
use_lora: true
lora_rank: 64           # Higher = more capacity, more VRAM
lora_alpha: 128         # Usually 2x lora_rank
lora_dropout: 0.05      # Regularization

# ============================================
# Training Configuration
# ============================================
num_epochs: 50
batch_size: 4                      # Per GPU (8 GPUs = 32 effective)
gradient_accumulation_steps: 4     # Effective batch = 4 * 4 * 8 = 128
learning_rate: 0.0001              # 1e-4
weight_decay: 0.01
warmup_steps: 1000
max_grad_norm: 1.0

# Mixed precision (bf16 for H100, fp16 for A100)
mixed_precision: "bf16"

# ============================================
# Data Configuration
# ============================================
data_dir: "./data"
image_size: 1024
num_workers: 8

# ============================================
# Loss Weights
# ============================================
diffusion_loss_weight: 1.0         # Main loss
perceptual_loss_weight: 0.1        # VGG perceptual
identity_loss_weight: 0.5          # Face preservation (important!)
garment_loss_weight: 0.2           # Clothing detail

# ============================================
# Logging & Checkpointing
# ============================================
log_every: 100                     # Log metrics every N steps
save_every: 1000                   # Save checkpoint every N steps
eval_every: 500                    # Validate every N steps
use_wandb: true
wandb_project: "mirrorx-vton"

# ============================================
# Reproducibility
# ============================================
seed: 42
