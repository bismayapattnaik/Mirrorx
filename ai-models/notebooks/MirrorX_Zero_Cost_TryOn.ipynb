{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MirrorX Zero-Cost Virtual Try-On\n",
        "\n",
        "**Run virtual try-on for FREE using Google Colab's GPU!**\n",
        "\n",
        "This notebook sets up:\n",
        "- OOTDiffusion for virtual try-on\n",
        "- InsightFace for face preservation\n",
        "- Gradio API for remote access\n",
        "\n",
        "**Cost: $0** (uses Colab's free T4 GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q transformers diffusers accelerate\n",
        "!pip install -q insightface onnxruntime-gpu\n",
        "!pip install -q gradio Pillow opencv-python numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install OOTDiffusion\n",
        "!pip install -q git+https://github.com/levihsu/OOTDiffusion.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download face swapper model\n",
        "!mkdir -p models\n",
        "!wget -q -O models/inswapper_128.onnx https://huggingface.co/deepinsight/inswapper/resolve/main/inswapper_128.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "import time\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load models\n",
        "print(\"Loading OOTDiffusion...\")\n",
        "from ootdiffusion import OOTDiffusionPipeline\n",
        "\n",
        "ootd_model = OOTDiffusionPipeline.from_pretrained(\n",
        "    \"levihsu/OOTDiffusion\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "print(\"OOTDiffusion loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load InsightFace for face preservation\n",
        "print(\"Loading InsightFace...\")\n",
        "from insightface.app import FaceAnalysis\n",
        "import insightface\n",
        "\n",
        "face_app = FaceAnalysis(\n",
        "    name=\"buffalo_l\",\n",
        "    providers=['CUDAExecutionProvider']\n",
        ")\n",
        "face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "# Load face swapper\n",
        "face_swapper = insightface.model_zoo.get_model(\n",
        "    'models/inswapper_128.onnx',\n",
        "    providers=['CUDAExecutionProvider']\n",
        ")\n",
        "\n",
        "print(\"InsightFace loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preserve_face(original_np, generated_np):\n",
        "    \"\"\"Swap original face into generated image.\"\"\"\n",
        "    try:\n",
        "        original_faces = face_app.get(original_np)\n",
        "        generated_faces = face_app.get(generated_np)\n",
        "        \n",
        "        if not original_faces or not generated_faces:\n",
        "            return generated_np\n",
        "        \n",
        "        result = face_swapper.get(\n",
        "            generated_np,\n",
        "            generated_faces[0],\n",
        "            original_faces[0],\n",
        "            paste_back=True\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Face preservation failed: {e}\")\n",
        "        return generated_np\n",
        "\n",
        "\n",
        "def virtual_tryon(\n",
        "    person_image,\n",
        "    clothing_image,\n",
        "    category=\"upperbody\",\n",
        "    preserve_face_flag=True,\n",
        "    num_steps=20,\n",
        "    guidance_scale=2.0\n",
        "):\n",
        "    \"\"\"Generate virtual try-on with face preservation.\"\"\"\n",
        "    start = time.time()\n",
        "    \n",
        "    # Resize images\n",
        "    person_image = person_image.resize((768, 1024), Image.Resampling.LANCZOS)\n",
        "    clothing_image = clothing_image.resize((768, 1024), Image.Resampling.LANCZOS)\n",
        "    \n",
        "    # Generate try-on\n",
        "    result = ootd_model(\n",
        "        model_image=person_image,\n",
        "        cloth_image=clothing_image,\n",
        "        category=category,\n",
        "        num_inference_steps=num_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "    )\n",
        "    result_image = result.images[0]\n",
        "    \n",
        "    # Preserve face\n",
        "    if preserve_face_flag:\n",
        "        person_np = np.array(person_image)\n",
        "        result_np = np.array(result_image)\n",
        "        result_np = preserve_face(person_np, result_np)\n",
        "        result_image = Image.fromarray(result_np)\n",
        "    \n",
        "    elapsed = time.time() - start\n",
        "    return result_image, f\"Generated in {elapsed:.2f}s\"\n",
        "\n",
        "print(\"Functions defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Gradio interface with public URL\n",
        "demo = gr.Interface(\n",
        "    fn=virtual_tryon,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Your Photo\"),\n",
        "        gr.Image(type=\"pil\", label=\"Clothing\"),\n",
        "        gr.Dropdown([\"upperbody\", \"lowerbody\", \"dress\"], value=\"upperbody\", label=\"Category\"),\n",
        "        gr.Checkbox(value=True, label=\"Preserve Face\"),\n",
        "        gr.Slider(10, 30, value=20, step=5, label=\"Quality Steps\"),\n",
        "        gr.Slider(1.0, 5.0, value=2.0, step=0.5, label=\"Guidance Scale\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Result\"),\n",
        "        gr.Textbox(label=\"Status\"),\n",
        "    ],\n",
        "    title=\"MirrorX Virtual Try-On (FREE)\",\n",
        "    description=\"Upload your photo and clothing to see how it looks on you!\",\n",
        ")\n",
        "\n",
        "# Launch with public URL (share=True creates a public link)\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the API\n",
        "\n",
        "Once launched, copy the public URL (e.g., `https://xxxxx.gradio.live`) and set it as:\n",
        "\n",
        "```\n",
        "SELF_HOSTED_TRYON_ENDPOINT=https://xxxxx.gradio.live/api/predict\n",
        "```\n",
        "\n",
        "Then call from your MirrorX backend:\n",
        "\n",
        "```typescript\n",
        "const response = await fetch('https://xxxxx.gradio.live/api/predict', {\n",
        "  method: 'POST',\n",
        "  headers: { 'Content-Type': 'application/json' },\n",
        "  body: JSON.stringify({\n",
        "    data: [personImageBase64, clothingImageBase64, 'upperbody', true, 20, 2.0]\n",
        "  })\n",
        "});\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
